COMPANY : CODTECH IT SOLUTIONS 
NAME : SYEDA ALIA SAMIA 
INTERN ID : CT04DG2786 
DOMAIN : DATA SCIENCE 
DURATION : 4 WEEKS 
MENTOR : NEELA SANTOSH

# END-TO-END-DATA-SCIENCE-PROJECT

## ðŸ“¦ Dataset

Due to GitHubâ€™s file size restrictions, the full dataset files are hosted externally.

  Download true.csv from Google Drive :
   https://drive.google.com/file/d/1cMvAkzkxamwFdtgmFWlWlLTmXEpbuHiq/view?usp=sharing
  
  Download fake.csv from Google Drive :
  https://drive.google.com/file/d/1IUDOJ_OYQnw069hcGHQ-8ctscIS1ujQ8/view?usp=sharing

How to Use:

Download both files

Place them in the same folder as your notebook

Make sure they are named exactly: true.csv and fake.csv

import pandas as pd
true_df = pd.read_csv("true.csv")
fake_df = pd.read_csv("fake.csv")


This project is developed as part of my internship and focuses on detecting fake news using machine learning techniques. The model classifies news articles as **real (true)** or **fake** based on their content.


## ðŸŽ¯ Objective

To create a machine learning pipeline that can distinguish between real and fake news articles using a dataset collected from reliable sources.


## ðŸ§  Technologies Used

- Python 3.10
- Pandas, NumPy
- Scikit-learn
- Natural Language Processing (NLP)
- Jupyter Notebook
- Google Drive (for dataset hosting)
- Git & GitHub (for version control)

- ðŸš€ How to Run

-Clone or download this repository

-Install requirements (pandas, scikit-learn, etc.)

-Download the datasets from Google Drive

-Open fake_news_detection.ipynb and run the cells

## âœ… Project Status

-  Data preprocessing (cleaning true and fake news)
-  Vectorization using TF-IDF
-  Model trained using Logistic Regression
-  Accuracy and classification report evaluated
-  Notebook completed
-  Model tested with sample input
-  Google Drive link for large files added

OUTPUT:
![Image](https://github.com/user-attachments/assets/a5bb3d19-30a9-4b57-a2ff-185f58b7d082)

